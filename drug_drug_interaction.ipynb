{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "254ce5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "[질문]\n",
      "코로나 백신과 타이레놀의 상호작용에 대한 최신 정보 알려줘\n",
      "\n",
      "[답변]\n",
      "현재까지의 정보에 따르면, 코로나19 백신과 타이레놀(아세트아미노펜) 사이에 특별한 상호작용이 보고된 바는 없습니다. 그러나, 백신 접종 후 발열이나 근육통과 같은 일시적인 부작용이 발생할 수 있으므로 이러한 증상이 나타날 경우에는 의료진의 지시에 따라 타이레놈을 복용하는 것이 권장될 수 있습니다. 하지만, 항열제나 진통제의 복용은 개인의 상황에 따라 다를 수 있으므로 의사나 약사와 상의하는 것이 좋습니다. 최신 정보를 확인하기 위해서는 의료 전문가의 조언을 따르는 것이 중요합니다.\n",
      "\n",
      "[출처]\n",
      "1. https://www.cdph.ca.gov/Programs/CID/DCDC/CDPH%20Document%20Library/COVID-19/Translations/Pfizer-COVID-19-Vaccine-Risks-and-Benefits--ko.pdf\n",
      "2. https://snuh.org/m/board/B003/view.do?bbs_no=6585&searchKey=&searchWord=2023&pageIndex=1\n",
      "3. https://www.sandiegocounty.gov/content/dam/sdc/hhsa/programs/phs/Epidemiology/covid19/vaccines/General_COVID-19_Vaccine_Myth_v_Fact_Korean.pdf\n",
      "4. https://www.jcohns.org/archive/view_article?pid=jcohns-33-2-92\n",
      "5. https://www.k-health.com/news/articleView.html?idxno=53360\n",
      "---\n",
      "[질문]\n",
      "Aspirin과 상호작용하는 약물은 무엇인가요?\n",
      "\n",
      "[답변]\n",
      "[답변]: 아스피린과 상호작용하는 약물로는 아세타졸아마이드, 염화 암모늄, 알코올, 토르부타마이드, 클로르프로파마이드, 와파린, 메토트렉세이트, 페니토인, 이부프로펜, 나프록센, 코르티코스테로이드, 리튬제제, 디곡신, 발프로산, 이뇨제, ACE 억제제 등이 있습니다. 이러한 약물들은 아스피린의 효과를 증가시키거나 감소시킬 수 있습니다.\n",
      "\n",
      "[출처]\n",
      "1. https://www.amc.seoul.kr/asan/depts/D123/K/bbsDetail.do?menuId=4634&contentId=271230\n",
      "2. https://www.health.kr/searchDrug/result_interaction.asp?drug_cd=2013073000013\n",
      "3. https://m.blog.naver.com/greenhospitalpr/221988418202\n",
      "4. https://common.health.kr/shared/healthkr/pharmreview/%EC%95%84%EC%8A%A4%ED%94%BC%EB%A6%B0(0).pdf\n",
      "5. https://ko.wikipedia.org/wiki/%EC%95%84%EC%8A%A4%ED%94%BC%EB%A6%B0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- API 키 로드 ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- 1. Graph State 정의 ---\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "# --- 2. Vector Store 및 Retriever 준비 ---\n",
    "loader = CSVLoader(file_path='db_drug_interactions.csv', encoding='utf-8')\n",
    "docs = loader.load()[:1000]\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "# --- 3. 웹 검색 도구 및 LLM 준비 ---\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# --- 4. LangGraph 노드 정의 (내부 print문 제거) ---\n",
    "\n",
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    if not documents:\n",
    "        return \"websearch\"\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"사용자의 질문에 대해 검색된 문서들이 관련성이 높으면 'yes', 아니면 'no'만 반환해줘.\\n\\n[문서]: {documents}\\n[질문]: {question}\"\n",
    "    )\n",
    "    grader_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    response = grader_chain.invoke({\"documents\": docs_str, \"question\": question})\n",
    "    if \"yes\" in response.content.lower():\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"websearch\"\n",
    "\n",
    "def generate(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"주어진 정보만을 바탕으로 질문에 대해 답변해줘.\\n\\n[정보]: {context}\\n[질문]: {question}\"\n",
    "    )\n",
    "    rag_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    generation = rag_chain.invoke({\"context\": docs_str, \"question\": question})\n",
    "    return {\"generation\": generation.content}\n",
    "\n",
    "def web_search(state):\n",
    "    question = state[\"question\"]\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_docs = [Document(page_content=d[\"content\"], metadata={\"source\": d[\"url\"]}) for d in web_results]\n",
    "    return {\"documents\": web_docs, \"question\": question}\n",
    "\n",
    "# --- 5. Graph 구성 ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\"generate\": \"generate\", \"websearch\": \"web_search\"},\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- 6. 최종 결과 출력 함수 (이미지 형식에 맞게 수정) ---\n",
    "def run_graph(question: str):\n",
    "    print(\"---\")\n",
    "    print(f\"[질문]\\n{question}\")\n",
    "\n",
    "    # invoke를 사용하여 최종 결과만 한 번에 받습니다.\n",
    "    final_state = app.invoke({\"question\": question})\n",
    "    \n",
    "    # 최종 답변 출력\n",
    "    print(\"\\n[답변]\")\n",
    "    print(final_state.get(\"generation\", \"답변을 생성하지 못했습니다.\"))\n",
    "    \n",
    "    # 출처 문서 출력\n",
    "    print(\"\\n[출처]\")\n",
    "    documents = final_state.get(\"documents\", [])\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"출처를 찾을 수 없습니다.\")\n",
    "    else:\n",
    "        # 중복된 출처 URL 제거 후 번호를 붙여 출력\n",
    "        unique_sources = set()\n",
    "        for doc in documents:\n",
    "            if hasattr(doc, 'metadata') and doc.metadata.get('source'):\n",
    "                unique_sources.add(doc.metadata['source'])\n",
    "        \n",
    "        if not unique_sources:\n",
    "            print(\"출처 URL을 찾을 수 없습니다.\")\n",
    "        else:\n",
    "            for i, source in enumerate(unique_sources, 1):\n",
    "                print(f\"{i}. {source}\")\n",
    "\n",
    "# --- 7. 직접 실행할 때만 작동하도록 수정 ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_graph(\"코로나 백신과 타이레놀의 상호작용에 대한 최신 정보 알려줘\")\n",
    "    run_graph(\"Aspirin과 상호작용하는 약물은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc06c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 그래프 시각화에 실패했습니다. 'pygraphviz' 라이브러리가 설치되어 있는지 확인해주세요. (에러: Install pygraphviz to draw graphs: `pip install pygraphviz`.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict\n",
    "\n",
    "# --- 시각화를 위해 추가 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- API 키 로드 ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- 1. Graph State 정의 ---\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "# --- 2. Vector Store 및 Retriever 준비 ---\n",
    "loader = CSVLoader(file_path='db_drug_interactions.csv', encoding='utf-8')\n",
    "docs = loader.load()[:1000]\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "# --- 3. 웹 검색 도구 및 LLM 준비 ---\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# --- 4. LangGraph 노드 정의 ---\n",
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    if not documents:\n",
    "        return \"websearch\"\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"사용자의 질문에 대해 검색된 문서들이 관련성이 높으면 'yes', 아니면 'no'만 반환해줘.\\n\\n[문서]: {documents}\\n[질문]: {question}\"\n",
    "    )\n",
    "    grader_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    response = grader_chain.invoke({\"documents\": docs_str, \"question\": question})\n",
    "    if \"yes\" in response.content.lower():\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"websearch\"\n",
    "\n",
    "def generate(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"주어진 정보만을 바탕으로 질문에 대해 답변해줘.\\n\\n[정보]: {context}\\n[질문]: {question}\"\n",
    "    )\n",
    "    rag_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    generation = rag_chain.invoke({\"context\": docs_str, \"question\": question})\n",
    "    return {\"generation\": generation.content}\n",
    "\n",
    "def web_search(state):\n",
    "    question = state[\"question\"]\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_docs = [Document(page_content=d[\"content\"], metadata={\"source\": d[\"url\"]}) for d in web_results]\n",
    "    return {\"documents\": web_docs, \"question\": question}\n",
    "\n",
    "# --- 5. Graph 구성 ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\"generate\": \"generate\", \"websearch\": \"web_search\"},\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# --- ⭐️ 그래프 시각화 코드 추가 ⭐️ ---\n",
    "try:\n",
    "    # 그래프 구조를 PNG 이미지 파일로 저장합니다.\n",
    "    graph_image_bytes = app.get_graph().draw_png()\n",
    "    with open(\"rag_graph.png\", \"wb\") as f:\n",
    "        f.write(graph_image_bytes)\n",
    "    print(\"✅ 그래프 이미지가 'rag_graph.png' 파일로 저장되었습니다.\")\n",
    "    # (선택사항) Jupyter Notebook 환경이라면 아래 코드로 바로 이미지를 표시할 수 있습니다.\n",
    "    # display(Image(graph_image_bytes))\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 그래프 시각화에 실패했습니다. 'pygraphviz' 라이브러리가 설치되어 있는지 확인해주세요. (에러: {e})\")\n",
    "\n",
    "# # --- (참고) 서버 실행 코드는 시각화 확인을 위해 주석 처리합니다. ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 서버 실행 대신 그래프 생성만 하려면 이 부분을 주석 처리하거나 삭제합니다.\n",
    "#     # uvicorn.run(...)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict\n",
    "\n",
    "# --- 서버 실행을 위한 라이브러리 ---\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "\n",
    "# --- LangChain 및 LangGraph 관련 라이브러리 ---\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. 환경 변수 로드 ---\n",
    "# .env 파일이 없다면 아래와 같이 직접 키를 설정해주세요.\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "load_dotenv()\n",
    "\n",
    "# --- 2. Graph State, 도구, LLM 준비 ---\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "# 예제 실행을 위해 가상의 CSV 파일을 생성합니다.\n",
    "with open('db_drug_interactions.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Drug,Interaction\\n\")\n",
    "    f.write(\"Aspirin,Ibuprofen can decrease the antiplatelet effect of aspirin.\\n\")\n",
    "    f.write(\"Warfarin,Vitamin K can reduce the anticoagulant effects of warfarin.\\n\")\n",
    "\n",
    "loader = CSVLoader(file_path='db_drug_interactions.csv', encoding='utf-8')\n",
    "docs = loader.load()\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 5})\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# --- 3. LangGraph 노드 정의 ---\n",
    "def retrieve(state):\n",
    "    print(\"--- 노드: retrieve ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"--- 노드: grade_documents (조건부 엣지) ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    if not documents or all(d.page_content == \"\" for d in documents):\n",
    "        print(\"-> 문서 없음, 웹 검색으로 라우팅\")\n",
    "        return \"websearch\"\n",
    "    prompt = PromptTemplate.from_template(\"사용자의 질문에 대해 검색된 문서들이 관련성이 높으면 'yes', 아니면 'no'만 반환해줘.\\n\\n[문서]: {documents}\\n[질문]: {question}\")\n",
    "    grader_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    response = grader_chain.invoke({\"documents\": docs_str, \"question\": question})\n",
    "    if \"yes\" in response.content.lower():\n",
    "        print(\"-> 문서 관련성 높음, 답변 생성으로 라우팅\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"-> 문서 관련성 낮음, 웹 검색으로 라우팅\")\n",
    "        return \"websearch\"\n",
    "\n",
    "def generate(state):\n",
    "    print(\"--- 노드: generate ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    prompt = PromptTemplate.from_template(\"주어진 정보만을 바탕으로 질문에 대해 답변해줘. 출처를 명시해줘.\\n\\n[정보]: {context}\\n[질문]: {question}\")\n",
    "    rag_chain = prompt | llm\n",
    "    docs_str = \"\\n\\n\".join([d.page_content for d in documents])\n",
    "    generation = rag_chain.invoke({\"context\": docs_str, \"question\": question})\n",
    "    return {\"generation\": generation.content}\n",
    "\n",
    "def web_search(state):\n",
    "    print(\"--- 노드: web_search ---\")\n",
    "    question = state[\"question\"]\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_docs = [Document(page_content=d[\"content\"], metadata={\"source\": d[\"url\"]}) for d in web_results]\n",
    "    return {\"documents\": web_docs, \"question\": question}\n",
    "\n",
    "\n",
    "# --- 4. Graph 구성 ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\"generate\": \"generate\", \"websearch\": \"web_search\"}\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d9b4428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grandalf in c:\\users\\mingyu\\desktop\\medisafe-companion\\.venv\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mingyu\\desktop\\medisafe-companion\\.venv\\lib\\site-packages (from grandalf) (3.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install grandalf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
