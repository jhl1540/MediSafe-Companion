import os
from dotenv import load_dotenv

# ìµœì‹  ê²½ë¡œ/íƒ€ì…
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# LangGraph ì‹œì‘ì  ë¶„ê¸°(START) ì‚¬ìš©
from langgraph.graph import StateGraph, START, END

from prompt_templates import single_drug_prompt, interaction_prompt

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ğŸ’¬ LLM ì¸ìŠ¤í„´ìŠ¤
llm = ChatOpenAI(
    api_key=api_key,   # openai_api_key=... ëŒ€ì‹  ìµœì‹  í‚¤ì›Œë“œ
    model="gpt-4o",
    temperature=0.5
)

# ğŸ§  ì•½ì‚¬ ì—­í• 
system_msg = SystemMessage(content="ë„ˆëŠ” ì•½ë¬¼ ì •ë³´ì™€ ìƒí˜¸ì‘ìš©ì„ ì „ë¬¸ê°€ì²˜ëŸ¼ ì„¤ëª…í•˜ëŠ” ì•½ì‚¬ì•¼.")

# ğŸŒ ìƒíƒœë¨¸ì‹  ë…¸ë“œ
def analyze_single_drug(state: dict):
    drug = state["drug1"]
    prompt_text = single_drug_prompt.format(drug=drug)
    messages = [system_msg, HumanMessage(content=prompt_text)]
    response = llm.invoke(messages)
    return {"result": response.content}

def analyze_two_drugs(state: dict):
    drug1 = state["drug1"]
    drug2 = state["drug2"]
    prompt_text = interaction_prompt.format(drug1=drug1, drug2=drug2)
    messages = [system_msg, HumanMessage(content=prompt_text)]
    response = llm.invoke(messages)
    return {"result": response.content}

# ğŸ”„ ê·¸ë˜í”„ êµ¬ì¶•
def build_graph():
    workflow = StateGraph(dict)

    workflow.add_node("analyze_single", analyze_single_drug)
    workflow.add_node("analyze_interaction", analyze_two_drugs)

    def should_use_interaction(state: dict):
        return "drug2" in state and state["drug2"] not in ("", None)

    workflow.add_conditional_edges(
        START,
        should_use_interaction,
        {
            True: "analyze_interaction",
            False: "analyze_single"
        }
    )

    workflow.add_edge("analyze_single", END)
    workflow.add_edge("analyze_interaction", END)

    return workflow.compile()
